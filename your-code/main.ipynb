{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:33:01.697816Z",
     "start_time": "2025-10-29T09:33:01.693484Z"
    }
   },
   "source": [
    "from IPython.display import display, HTML\n",
    "from keras.src.ops import dtype\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Natural Language Processing\n",
    "### SMS: SPAM or HAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:33:01.714016Z",
     "start_time": "2025-10-29T09:33:01.711941Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read Data for the Fraudulent Email Kaggle Challenge\n",
    "- Reduce the training set to speead up development. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:33:01.764748Z",
     "start_time": "2025-10-29T09:33:01.718988Z"
    }
   },
   "source": [
    "## Read Data for the Fraudulent Email Kaggle Challenge\n",
    "data = pd.read_csv(\"../data/kg_train.csv\",encoding='latin-1')\n",
    "\n",
    "# Reduce the training set to speed up development. \n",
    "# Modify for final system\n",
    "data = data.head(1000)\n",
    "print(data.shape)\n",
    "data.fillna(\"\",inplace=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:33:01.769731Z",
     "start_time": "2025-10-29T09:33:01.767007Z"
    }
   },
   "cell_type": "code",
   "source": "data.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...      1\n",
       "1                                           Will do.      0\n",
       "2  Nora--Cheryl has emailed dozens of memos about...      0\n",
       "3  Dear Sir=2FMadam=2C I know that this proposal ...      1\n",
       "4                                                fyi      0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will do.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nora--Cheryl has emailed dozens of memos about...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Sir=2FMadam=2C I know that this proposal ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fyi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's divide the training and test set into two partitions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:33:01.789327Z",
     "start_time": "2025-10-29T09:33:01.786797Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data[['text']]\n",
    "y = data[['label']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:33:01.815384Z",
     "start_time": "2025-10-29T09:33:01.812769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(X_train.shape)\n",
    "print(X_train.head())\n",
    "print(X_test.shape)\n",
    "print(X_test.head())\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1)\n",
      "                                                  text\n",
      "29   ----------- REGARDS, MR NELSON SMITH.KINDLY RE...\n",
      "535  I have not been able to reach oscar this am. W...\n",
      "695  ; Huma Abedin B6I'm checking with Pat on the 5...\n",
      "557  I can have it announced here on Monday - can't...\n",
      "836      BANK OF AFRICAAGENCE SAN PEDRO14 BP 1210 S...\n",
      "(200, 1)\n",
      "                                                  text\n",
      "521  Dear Sir=2C I wish you go through this offer t...\n",
      "737  To take your mind off the Balkans for a second...\n",
      "740                       Pls keep the updates coming!\n",
      "660  </STRONG><STRONG>CHRIST BETHEL HOSPITAL<BR>11 ...\n",
      "411  sbwhoeopFriday February 5 2010 7:11 AMHRe: Bra...\n",
      "(800, 1)\n",
      "(200, 1)\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:33:01.822060Z",
     "start_time": "2025-10-29T09:33:01.820168Z"
    }
   },
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "print(string.punctuation)\n",
    "print(stopwords.words(\"english\")[100:110])\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snowball = SnowballStemmer('english')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "['needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on']\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we have to clean the html code removing words\n",
    "\n",
    "- First we remove inline JavaScript/CSS\n",
    "- Then we remove html comments. This has to be done before removing regular tags since comments can contain '>' characters\n",
    "- Next we can remove the remaining tags"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:33:01.836073Z",
     "start_time": "2025-10-29T09:33:01.830964Z"
    }
   },
   "source": [
    "import re\n",
    "import html\n",
    "\n",
    "def remove_html_javascript(text):\n",
    "    # Remove <script> or <style> blocks\n",
    "    text = re.sub(r'<(script|style).*?>.*?</\\1>', '', text, flags=re.DOTALL)\n",
    "\n",
    "    #Unescape HTML entities (convert &nbsp; → space, &amp; → &, etc.)\n",
    "    text = html.unescape(text)\n",
    "\n",
    "    # Remove HTML comments\n",
    "    text = re.sub(r'<!--.*?-->', '', text, flags=re.DOTALL)\n",
    "\n",
    "    # Remove remaining HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(remove_html_javascript)\n",
    "X_test['text'] = X_test['text'].apply(remove_html_javascript)"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:33:01.840490Z",
     "start_time": "2025-10-29T09:33:01.837994Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  text\n",
       "29   ----------- REGARDS, MR NELSON SMITH.KINDLY RE...\n",
       "535  I have not been able to reach oscar this am. W...\n",
       "695  ; Huma Abedin B6I'm checking with Pat on the 5...\n",
       "557  I can have it announced here on Monday - can't...\n",
       "836      BANK OF AFRICAAGENCE SAN PEDRO14 BP 1210 S..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>----------- REGARDS, MR NELSON SMITH.KINDLY RE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>I have not been able to reach oscar this am. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>; Huma Abedin B6I'm checking with Pat on the 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>I can have it announced here on Monday - can't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>BANK OF AFRICAAGENCE SAN PEDRO14 BP 1210 S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove all the special characters\n",
    "    \n",
    "- Remove numbers\n",
    "    \n",
    "- Remove all single characters\n",
    " \n",
    "- Remove single characters from the start\n",
    "\n",
    "- Substitute multiple spaces with single space\n",
    "\n",
    "- Remove prefixed 'b'\n",
    "\n",
    "- Convert to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:42:38.258959Z",
     "start_time": "2025-10-29T09:42:38.206677Z"
    }
   },
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Replace any character that is **not** a letter (a-z or A-Z) or space with a space.\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "\n",
    "    # Replace any sequence of digits (0-9) with a space.\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "\n",
    "    # Remove Python-style byte/unicode prefixes (b\"text\", u'text')\n",
    "    text = re.sub(r\"^[bu][\\\"']?(.*?)[\\\"']?$\", r'\\1', text)\n",
    "\n",
    "    # Replace single-letter words (isolated letters) with a space.\n",
    "    text = re.sub(r'\\b[a-zA-Z]\\b', ' ', text)\n",
    "\n",
    "    # Remove a single letter at the **start** of the string followed by space(s).\n",
    "    text = re.sub(r'^[a-zA-Z]\\s+', '', text)\n",
    "\n",
    "    # Collapse multiple whitespace characters into a single space.\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Remove prefix “b ” or “u ” if present (from byte or unicode string representations).\n",
    "    text = re.sub(r'^[bu]\\s+', '', text)\n",
    "    # Remove prefix “b'...’” or “u'...’” and keep the content inside the quotes.\n",
    "    text = re.sub(r\"^[bu]'(.*)'$\", r'\\1', text)\n",
    "    # Remove prefix “b\\\"...\\\"” or “u\\\"...\\\"” and keep the content inside the quotes.\n",
    "    text = re.sub(r'^[bu]\"(.*)\"$', r'\\1', text)\n",
    "\n",
    "    # Convert everything to lowercase and strip whitespace from ends.\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(clean_text)\n",
    "X_test['text'] = X_test['text'].apply(clean_text)"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:42:38.967070Z",
     "start_time": "2025-10-29T09:42:38.959748Z"
    }
   },
   "cell_type": "code",
   "source": "print(X_train.head)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                   text  money_mark  \\\n",
      "29   regard mr nelson smith kindly reply private em...           0   \n",
      "535         able reach oscar supposed send pdb receive           0   \n",
      "695  huma abedin checking pat work jack jake rest a...           0   \n",
      "557                             announced monday today           0   \n",
      "836  ank africaagence san pedro bp san pedro cote i...           1   \n",
      "..                                                 ...         ...   \n",
      "106  adama ibrahim tout savoir sur la curit de votr...           0   \n",
      "270                                      mean schedule           0   \n",
      "860  dear friend compliment guess letter may come s...           1   \n",
      "435  dear president fdirector name mr micheal ipenz...           1   \n",
      "102  let know today tomorrow work would rather find...           0   \n",
      "\n",
      "     suspicious_words  text_len  \n",
      "29                  0        79  \n",
      "535                 0        42  \n",
      "695                 0        76  \n",
      "557                 0        22  \n",
      "836                 1      1050  \n",
      "..                ...       ...  \n",
      "106                 0        99  \n",
      "270                 0        13  \n",
      "860                 1      1452  \n",
      "435                 1      2097  \n",
      "102                 0       124  \n",
      "\n",
      "[800 rows x 4 columns]>\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Now let's work on removing stopwords\n",
    "Remove the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:42:40.628681Z",
     "start_time": "2025-10-29T09:42:40.542325Z"
    }
   },
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "def clean_stopwords(text):\n",
    "    words = [w for w in text.split() if w not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(clean_stopwords)\n",
    "X_test['text'] = X_test['text'].apply(clean_stopwords)"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:42:41.097883Z",
     "start_time": "2025-10-29T09:42:41.094254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(X_train.head)\n",
    "print(X_test.head)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                   text  money_mark  \\\n",
      "29   regard mr nelson smith kindly reply private em...           0   \n",
      "535         able reach oscar supposed send pdb receive           0   \n",
      "695  huma abedin checking pat work jack jake rest a...           0   \n",
      "557                             announced monday today           0   \n",
      "836  ank africaagence san pedro bp san pedro cote i...           1   \n",
      "..                                                 ...         ...   \n",
      "106  adama ibrahim tout savoir sur la curit de votr...           0   \n",
      "270                                      mean schedule           0   \n",
      "860  dear friend compliment guess letter may come s...           1   \n",
      "435  dear president fdirector name mr micheal ipenz...           1   \n",
      "102  let know today tomorrow work would rather find...           0   \n",
      "\n",
      "     suspicious_words  text_len  \n",
      "29                  0        79  \n",
      "535                 0        42  \n",
      "695                 0        76  \n",
      "557                 0        22  \n",
      "836                 1      1050  \n",
      "..                ...       ...  \n",
      "106                 0        99  \n",
      "270                 0        13  \n",
      "860                 1      1452  \n",
      "435                 1      2097  \n",
      "102                 0       124  \n",
      "\n",
      "[800 rows x 4 columns]>\n",
      "<bound method NDFrame.head of                                                   text  money_mark  \\\n",
      "521  dear sir wish go offer consider partner ei mr ...           0   \n",
      "737  take mind balkan second see great plug global ...           0   \n",
      "740                             pls keep update coming           0   \n",
      "660  christ bethel hospital rue abobote abidjanivor...           0   \n",
      "411  sbwhoeopfriday february amhre bravo brava issu...           0   \n",
      "..                                                 ...         ...   \n",
      "408                   sorry yes exactlywe shy tomorrow           0   \n",
      "332  dear cgood day ei know message come suprise co...           1   \n",
      "208                                                fyi           0   \n",
      "613  greeting dear friend please permit contact med...           0   \n",
      "78                     car way airport talk call berry           0   \n",
      "\n",
      "     suspicious_words  text_len  \n",
      "521                 1      1324  \n",
      "737                 0       323  \n",
      "740                 0        22  \n",
      "660                 1      1207  \n",
      "411                 0       162  \n",
      "..                ...       ...  \n",
      "408                 0        32  \n",
      "332                 1       865  \n",
      "208                 0         3  \n",
      "613                 1      1084  \n",
      "78                  0        31  \n",
      "\n",
      "[200 rows x 4 columns]>\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tame Your Text with Lemmatization\n",
    "Break sentences into words, then use lemmatization to reduce them to their base form (e.g., \"running\" becomes \"run\"). See how this creates cleaner data for analysis!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:42:43.570652Z",
     "start_time": "2025-10-29T09:42:43.283405Z"
    }
   },
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    words = [wordnet.lemmatize(token) for token in word_tokenize(text)]\n",
    "    return ' '.join(words)\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(lemmatize_text)\n",
    "X_test['text'] = X_test['text'].apply(lemmatize_text)"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:42:43.756983Z",
     "start_time": "2025-10-29T09:42:43.753147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"X_train_lemmatized\")\n",
    "print(X_train.head())\n",
    "print(\"X_test_lemmatized\")\n",
    "print(X_test.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_lemmatized\n",
      "                                                  text  money_mark  \\\n",
      "29   regard mr nelson smith kindly reply private em...           0   \n",
      "535         able reach oscar supposed send pdb receive           0   \n",
      "695  huma abedin checking pat work jack jake rest a...           0   \n",
      "557                             announced monday today           0   \n",
      "836  ank africaagence san pedro bp san pedro cote i...           1   \n",
      "\n",
      "     suspicious_words  text_len  \n",
      "29                  0        79  \n",
      "535                 0        42  \n",
      "695                 0        76  \n",
      "557                 0        22  \n",
      "836                 1      1050  \n",
      "X_test_lemmatized\n",
      "                                                  text  money_mark  \\\n",
      "521  dear sir wish go offer consider partner ei mr ...           0   \n",
      "737  take mind balkan second see great plug global ...           0   \n",
      "740                             pls keep update coming           0   \n",
      "660  christ bethel hospital rue abobote abidjanivor...           0   \n",
      "411  sbwhoeopfriday february amhre bravo brava issu...           0   \n",
      "\n",
      "     suspicious_words  text_len  \n",
      "521                 1      1324  \n",
      "737                 0       323  \n",
      "740                 0        22  \n",
      "660                 1      1207  \n",
      "411                 0       162  \n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words\n",
    "Let's get the 10 top words in ham and spam messages (**EXPLORATORY DATA ANALYSIS**)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:42:46.073571Z",
     "start_time": "2025-10-29T09:42:46.045677Z"
    }
   },
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "def get_top_n_words(text_series, n=10):\n",
    "    all_text = ' '.join(text_series)\n",
    "    words = all_text.split()\n",
    "    word_counts = Counter(words)\n",
    "    return word_counts.most_common(n)\n",
    "\n",
    "# Convert X_train and y_train to DataFrame\n",
    "df_train = pd.concat([X_train['text'], y_train['label']], axis=1)\n",
    "df_test = pd.concat([X_test['text'], y_test['label']], axis=1)\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "\n",
    "# Top 10 words in ham messages\n",
    "top_10_ham = get_top_n_words(df_all[df_all['label'] == 0]['text'])\n",
    "top_10_spam = get_top_n_words(df_all[df_all['label'] == 1]['text'])\n",
    "\n",
    "top_10_ham = pd.DataFrame(top_10_ham, columns=['words', 'count'])\n",
    "top_10_spam = pd.DataFrame(top_10_spam, columns=['words', 'count'])\n",
    "\n",
    "print(\"Top 10 Ham Words:\")\n",
    "print(top_10_ham)\n",
    "print(\"Top 10 Spam Words:\")\n",
    "print(top_10_spam)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Ham Words:\n",
      "       words  count\n",
      "0      state    136\n",
      "1         pm    127\n",
      "2      would    107\n",
      "3  president     99\n",
      "4       time     95\n",
      "5       call     94\n",
      "6         mr     91\n",
      "7      obama     84\n",
      "8    percent     81\n",
      "9  secretary     79\n",
      "Top 10 Spam Words:\n",
      "         words  count\n",
      "0        money    981\n",
      "1      account    895\n",
      "2         bank    799\n",
      "3         fund    781\n",
      "4  transaction    549\n",
      "5     business    513\n",
      "6      country    508\n",
      "7           mr    489\n",
      "8      million    460\n",
      "9     transfer    422\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra features"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:33:02.383518Z",
     "start_time": "2025-10-29T09:33:02.372790Z"
    }
   },
   "source": [
    "# We add to the original dataframe two additional indicators (money symbols and suspicious words).\n",
    "money_simbol_list = \"|\".join([\"euro\",\"dollar\",\"pound\",\"€\",r\"\\$\"])\n",
    "suspicious_words = \"|\".join([\"free\",\"cheap\",\"sex\",\"money\",\"account\",\"bank\",\"fund\",\"transfer\",\"transaction\",\"win\",\"deposit\",\"password\"])\n",
    "\n",
    "X_train['money_mark'] = X_train['text'].str.contains(money_simbol_list)*1\n",
    "X_train['suspicious_words'] = X_train['text'].str.contains(suspicious_words)*1\n",
    "X_train['text_len'] = X_train['text'].apply(lambda x: len(x))\n",
    "\n",
    "X_test['money_mark'] = X_test['text'].str.contains(money_simbol_list)*1\n",
    "X_test['suspicious_words'] = X_test['text'].str.contains(suspicious_words)*1\n",
    "X_test['text_len'] = X_test['text'].apply(lambda x: len(x))\n",
    "\n",
    "X_train.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  text  money_mark  \\\n",
       "29   regard mr nelson smith kindly reply private em...           0   \n",
       "535         able reach oscar supposed send pdb receive           0   \n",
       "695  huma abedin checking pat work jack jake rest a...           0   \n",
       "557                             announced monday today           0   \n",
       "836  bank africaagence san pedro bp san pedro cote ...           1   \n",
       "\n",
       "     suspicious_words  text_len  \n",
       "29                  0        79  \n",
       "535                 0        42  \n",
       "695                 0        76  \n",
       "557                 0        22  \n",
       "836                 1      1050  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>money_mark</th>\n",
       "      <th>suspicious_words</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>regard mr nelson smith kindly reply private em...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>able reach oscar supposed send pdb receive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>huma abedin checking pat work jack jake rest a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>announced monday today</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>bank africaagence san pedro bp san pedro cote ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How would work the Bag of Words with Count Vectorizer concept?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:33:02.400569Z",
     "start_time": "2025-10-29T09:33:02.399279Z"
    }
   },
   "source": [
    "# Your code"
   ],
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "- Load the vectorizer\n",
    "\n",
    "- Vectorize all dataset\n",
    "\n",
    "- print the shape of the vetorized dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:33:02.425785Z",
     "start_time": "2025-10-29T09:33:02.424225Z"
    }
   },
   "source": [
    "# Your code"
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And the Train a Classifier?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:33:02.437413Z",
     "start_time": "2025-10-29T09:33:02.436075Z"
    }
   },
   "source": [
    "# Your code"
   ],
   "outputs": [],
   "execution_count": 62
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Task - Implement a SPAM/HAM classifier\n",
    "\n",
    "https://www.kaggle.com/t/b384e34013d54d238490103bc3c360ce\n",
    "\n",
    "The classifier can not be changed!!! It must be the MultinimialNB with default parameters!\n",
    "\n",
    "Your task is to **find the most relevant features**.\n",
    "\n",
    "For example, you can test the following options and check which of them performs better:\n",
    "- Using \"Bag of Words\" only\n",
    "- Using \"TF-IDF\" only\n",
    "- Bag of Words + extra flags (money_mark, suspicious_words, text_len)\n",
    "- TF-IDF + extra flags\n",
    "\n",
    "\n",
    "You can work with teams of two persons (recommended)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T09:33:02.443395Z",
     "start_time": "2025-10-29T09:33:02.442139Z"
    }
   },
   "source": [
    "# Your code"
   ],
   "outputs": [],
   "execution_count": 63
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
