{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:01.583401Z",
     "start_time": "2025-10-29T11:47:01.580054Z"
    }
   },
   "source": [
    "from IPython.display import display, HTML\n",
    "from keras.src.ops import dtype\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Natural Language Processing\n",
    "### SMS: SPAM or HAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:01.598250Z",
     "start_time": "2025-10-29T11:47:01.596847Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read Data for the Fraudulent Email Kaggle Challenge\n",
    "- Reduce the training set to speead up development. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:01.642121Z",
     "start_time": "2025-10-29T11:47:01.603633Z"
    }
   },
   "source": [
    "## Read Data for the Fraudulent Email Kaggle Challenge\n",
    "data = pd.read_csv(\"../data/kg_train.csv\",encoding='latin-1')\n",
    "\n",
    "# Reduce the training set to speed up development. \n",
    "# Modify for final system\n",
    "data = data.head(1000)\n",
    "print(data.shape)\n",
    "data.fillna(\"\",inplace=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:01.662183Z",
     "start_time": "2025-10-29T11:47:01.656723Z"
    }
   },
   "cell_type": "code",
   "source": "data.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...      1\n",
       "1                                           Will do.      0\n",
       "2  Nora--Cheryl has emailed dozens of memos about...      0\n",
       "3  Dear Sir=2FMadam=2C I know that this proposal ...      1\n",
       "4                                                fyi      0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will do.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nora--Cheryl has emailed dozens of memos about...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Sir=2FMadam=2C I know that this proposal ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fyi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's divide the training and test set into two partitions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:01.746070Z",
     "start_time": "2025-10-29T11:47:01.669865Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data[['text']]\n",
    "y = data[['label']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:01.766647Z",
     "start_time": "2025-10-29T11:47:01.764302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(X_train.shape)\n",
    "print(X_train.head())\n",
    "print(X_test.shape)\n",
    "print(X_test.head())\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1)\n",
      "                                                  text\n",
      "29   ----------- REGARDS, MR NELSON SMITH.KINDLY RE...\n",
      "535  I have not been able to reach oscar this am. W...\n",
      "695  ; Huma Abedin B6I'm checking with Pat on the 5...\n",
      "557  I can have it announced here on Monday - can't...\n",
      "836      BANK OF AFRICAAGENCE SAN PEDRO14 BP 1210 S...\n",
      "(200, 1)\n",
      "                                                  text\n",
      "521  Dear Sir=2C I wish you go through this offer t...\n",
      "737  To take your mind off the Balkans for a second...\n",
      "740                       Pls keep the updates coming!\n",
      "660  </STRONG><STRONG>CHRIST BETHEL HOSPITAL<BR>11 ...\n",
      "411  sbwhoeopFriday February 5 2010 7:11 AMHRe: Bra...\n",
      "(800, 1)\n",
      "(200, 1)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:02.004547Z",
     "start_time": "2025-10-29T11:47:01.806803Z"
    }
   },
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "print(string.punctuation)\n",
    "print(stopwords.words(\"english\")[100:110])\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snowball = SnowballStemmer('english')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "['needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on']\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we have to clean the html code removing words\n",
    "\n",
    "- First we remove inline JavaScript/CSS\n",
    "- Then we remove html comments. This has to be done before removing regular tags since comments can contain '>' characters\n",
    "- Next we can remove the remaining tags"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:02.016541Z",
     "start_time": "2025-10-29T11:47:02.011737Z"
    }
   },
   "source": [
    "import re\n",
    "import html\n",
    "\n",
    "def remove_html_javascript(text):\n",
    "    # Remove <script> or <style> blocks\n",
    "    text = re.sub(r'<(script|style).*?>.*?</\\1>', '', text, flags=re.DOTALL)\n",
    "\n",
    "    #Unescape HTML entities (convert &nbsp; → space, &amp; → &, etc.)\n",
    "    text = html.unescape(text)\n",
    "\n",
    "    # Remove HTML comments\n",
    "    text = re.sub(r'<!--.*?-->', '', text, flags=re.DOTALL)\n",
    "\n",
    "    # Remove remaining HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(remove_html_javascript)\n",
    "X_test['text'] = X_test['text'].apply(remove_html_javascript)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:02.023974Z",
     "start_time": "2025-10-29T11:47:02.020799Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  text\n",
       "29   ----------- REGARDS, MR NELSON SMITH.KINDLY RE...\n",
       "535  I have not been able to reach oscar this am. W...\n",
       "695  ; Huma Abedin B6I'm checking with Pat on the 5...\n",
       "557  I can have it announced here on Monday - can't...\n",
       "836      BANK OF AFRICAAGENCE SAN PEDRO14 BP 1210 S..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>----------- REGARDS, MR NELSON SMITH.KINDLY RE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>I have not been able to reach oscar this am. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>; Huma Abedin B6I'm checking with Pat on the 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>I can have it announced here on Monday - can't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>BANK OF AFRICAAGENCE SAN PEDRO14 BP 1210 S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove all the special characters\n",
    "    \n",
    "- Remove numbers\n",
    "    \n",
    "- Remove all single characters\n",
    " \n",
    "- Remove single characters from the start\n",
    "\n",
    "- Substitute multiple spaces with single space\n",
    "\n",
    "- Remove prefixed 'b'\n",
    "\n",
    "- Convert to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:02.118003Z",
     "start_time": "2025-10-29T11:47:02.054898Z"
    }
   },
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Replace any character that is **not** a letter (a-z or A-Z) or space with a space.\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "\n",
    "    # Replace any sequence of digits (0-9) with a space.\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "\n",
    "    # Remove Python-style byte/unicode prefixes (b\"text\", u'text')\n",
    "    text = re.sub(r\"^[bu][\\\"']?(.*?)[\\\"']?$\", r'\\1', text)\n",
    "\n",
    "    # Replace single-letter words (isolated letters) with a space.\n",
    "    text = re.sub(r'\\b[a-zA-Z]\\b', ' ', text)\n",
    "\n",
    "    # Remove a single letter at the **start** of the string followed by space(s).\n",
    "    text = re.sub(r'^[a-zA-Z]\\s+', '', text)\n",
    "\n",
    "    # Collapse multiple whitespace characters into a single space.\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Remove prefix “b ” or “u ” if present (from byte or unicode string representations).\n",
    "    text = re.sub(r'^[bu]\\s+', '', text)\n",
    "    # Remove prefix “b'...’” or “u'...’” and keep the content inside the quotes.\n",
    "    text = re.sub(r\"^[bu]'(.*)'$\", r'\\1', text)\n",
    "    # Remove prefix “b\\\"...\\\"” or “u\\\"...\\\"” and keep the content inside the quotes.\n",
    "    text = re.sub(r'^[bu]\"(.*)\"$', r'\\1', text)\n",
    "\n",
    "    # Convert everything to lowercase and strip whitespace from ends.\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(clean_text)\n",
    "X_test['text'] = X_test['text'].apply(clean_text)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:02.213397Z",
     "start_time": "2025-10-29T11:47:02.210901Z"
    }
   },
   "cell_type": "code",
   "source": "print(X_train.head)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                   text\n",
      "29   regards mr nelson smith kindly reply me on my ...\n",
      "535  have not been able to reach oscar this am we a...\n",
      "695  huma abedin checking with pat on the will work...\n",
      "557     can have it announced here on monday can today\n",
      "836  bank of africaagence san pedro bp san pedro co...\n",
      "..                                                 ...\n",
      "106  adama ibrahim tout savoir sur la curit de votr...\n",
      "270              what does that mean for our schedules\n",
      "860  dear friend my compliment to you guess this le...\n",
      "435  dear president fdirector my name is mr micheal...\n",
      "102  let me know if today or tomorrow works for you...\n",
      "\n",
      "[800 rows x 1 columns]>\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Now let's work on removing stopwords\n",
    "Remove the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:02.342750Z",
     "start_time": "2025-10-29T11:47:02.224019Z"
    }
   },
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "def clean_stopwords(text):\n",
    "    words = [w for w in text.split() if w not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(clean_stopwords)\n",
    "X_test['text'] = X_test['text'].apply(clean_stopwords)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:02.350456Z",
     "start_time": "2025-10-29T11:47:02.347772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(X_train.head)\n",
    "print(X_test.head)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                   text\n",
      "29   regards mr nelson smith kindly reply private e...\n",
      "535         able reach oscar supposed send pdb receive\n",
      "695  huma abedin checking pat work jack jake rest a...\n",
      "557                             announced monday today\n",
      "836  bank africaagence san pedro bp san pedro cote ...\n",
      "..                                                 ...\n",
      "106  adama ibrahim tout savoir sur la curit de votr...\n",
      "270                                     mean schedules\n",
      "860  dear friend compliment guess letter may come s...\n",
      "435  dear president fdirector name mr micheal ipenz...\n",
      "102  let know today tomorrow works would rather fin...\n",
      "\n",
      "[800 rows x 1 columns]>\n",
      "<bound method NDFrame.head of                                                   text\n",
      "521  dear sir wish go offer consider partner ei mr ...\n",
      "737  take mind balkans second see great plug global...\n",
      "740                            pls keep updates coming\n",
      "660  christ bethel hospital rue abobote abidjanivor...\n",
      "411  sbwhoeopfriday february amhre bravo brava issu...\n",
      "..                                                 ...\n",
      "408                   sorry yes exactlywe shy tomorrow\n",
      "332  dear cgood day ei know message come suprise co...\n",
      "208                                                fyi\n",
      "613  greetings dear friend please permit contact me...\n",
      "78                     car way airport talk call berry\n",
      "\n",
      "[200 rows x 1 columns]>\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tame Your Text with Lemmatization\n",
    "Break sentences into words, then use lemmatization to reduce them to their base form (e.g., \"running\" becomes \"run\"). See how this creates cleaner data for analysis!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:03.524660Z",
     "start_time": "2025-10-29T11:47:02.358554Z"
    }
   },
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    words = [wordnet.lemmatize(token) for token in word_tokenize(text)]\n",
    "    return ' '.join(words)\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(lemmatize_text)\n",
    "X_test['text'] = X_test['text'].apply(lemmatize_text)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:03.537081Z",
     "start_time": "2025-10-29T11:47:03.534708Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"X_train_lemmatized\")\n",
    "print(X_train.head())\n",
    "print(\"X_test_lemmatized\")\n",
    "print(X_test.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_lemmatized\n",
      "                                                  text\n",
      "29   regard mr nelson smith kindly reply private em...\n",
      "535         able reach oscar supposed send pdb receive\n",
      "695  huma abedin checking pat work jack jake rest a...\n",
      "557                             announced monday today\n",
      "836  bank africaagence san pedro bp san pedro cote ...\n",
      "X_test_lemmatized\n",
      "                                                  text\n",
      "521  dear sir wish go offer consider partner ei mr ...\n",
      "737  take mind balkan second see great plug global ...\n",
      "740                             pls keep update coming\n",
      "660  christ bethel hospital rue abobote abidjanivor...\n",
      "411  sbwhoeopfriday february amhre bravo brava issu...\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words\n",
    "Let's get the 10 top words in ham and spam messages (**EXPLORATORY DATA ANALYSIS**)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:03.558235Z",
     "start_time": "2025-10-29T11:47:03.543865Z"
    }
   },
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "def get_top_n_words(text_series, n=10):\n",
    "    all_text = ' '.join(text_series)\n",
    "    words = all_text.split()\n",
    "    word_counts = Counter(words)\n",
    "    return word_counts.most_common(n)\n",
    "\n",
    "# Convert X_train and y_train to DataFrame\n",
    "df_train = pd.concat([X_train['text'], y_train['label']], axis=1)\n",
    "df_test = pd.concat([X_test['text'], y_test['label']], axis=1)\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "\n",
    "# Top 10 words in ham messages\n",
    "top_10_ham = get_top_n_words(df_all[df_all['label'] == 0]['text'])\n",
    "top_10_spam = get_top_n_words(df_all[df_all['label'] == 1]['text'])\n",
    "\n",
    "top_10_ham = pd.DataFrame(top_10_ham, columns=['words', 'count'])\n",
    "top_10_spam = pd.DataFrame(top_10_spam, columns=['words', 'count'])\n",
    "\n",
    "print(\"Top 10 Ham Words:\")\n",
    "print(top_10_ham)\n",
    "print(\"Top 10 Spam Words:\")\n",
    "print(top_10_spam)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Ham Words:\n",
      "       words  count\n",
      "0      state    136\n",
      "1         pm    127\n",
      "2      would    107\n",
      "3  president     99\n",
      "4       time     95\n",
      "5       call     94\n",
      "6         mr     91\n",
      "7      obama     84\n",
      "8    percent     81\n",
      "9  secretary     79\n",
      "Top 10 Spam Words:\n",
      "         words  count\n",
      "0        money    981\n",
      "1      account    895\n",
      "2         bank    800\n",
      "3         fund    781\n",
      "4            u    734\n",
      "5  transaction    549\n",
      "6     business    514\n",
      "7      country    508\n",
      "8           mr    489\n",
      "9      million    460\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra features"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:03.573772Z",
     "start_time": "2025-10-29T11:47:03.562438Z"
    }
   },
   "source": [
    "# We add to the original dataframe two additional indicators (money symbols and suspicious words).\n",
    "money_simbol_list = \"|\".join([\"euro\",\"dollar\",\"pound\",\"€\",r\"\\$\"])\n",
    "suspicious_words = \"|\".join([\"free\",\"cheap\",\"sex\",\"money\",\"account\",\"bank\",\"fund\",\"transfer\",\"transaction\",\"win\",\"deposit\",\"password\"])\n",
    "\n",
    "X_train['money_mark'] = X_train['text'].str.contains(money_simbol_list)*1\n",
    "X_train['suspicious_words'] = X_train['text'].str.contains(suspicious_words)*1\n",
    "X_train['text_len'] = X_train['text'].apply(lambda x: len(x))\n",
    "\n",
    "X_test['money_mark'] = X_test['text'].str.contains(money_simbol_list)*1\n",
    "X_test['suspicious_words'] = X_test['text'].str.contains(suspicious_words)*1\n",
    "X_test['text_len'] = X_test['text'].apply(lambda x: len(x))\n",
    "\n",
    "X_train.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  text  money_mark  \\\n",
       "29   regard mr nelson smith kindly reply private em...           0   \n",
       "535         able reach oscar supposed send pdb receive           0   \n",
       "695  huma abedin checking pat work jack jake rest a...           0   \n",
       "557                             announced monday today           0   \n",
       "836  bank africaagence san pedro bp san pedro cote ...           1   \n",
       "\n",
       "     suspicious_words  text_len  \n",
       "29                  0        79  \n",
       "535                 0        42  \n",
       "695                 0        76  \n",
       "557                 0        22  \n",
       "836                 1      1050  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>money_mark</th>\n",
       "      <th>suspicious_words</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>regard mr nelson smith kindly reply private em...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>able reach oscar supposed send pdb receive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>huma abedin checking pat work jack jake rest a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>announced monday today</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>bank africaagence san pedro bp san pedro cote ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How would work the Bag of Words with Count Vectorizer concept?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:53:40.047028Z",
     "start_time": "2025-10-29T11:53:39.980954Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#let's take only the most common 1000 words\n",
    "bow_vect = CountVectorizer(max_features=1000)\n",
    "\n",
    "# vectorize training data\n",
    "X_train_bow = bow_vect.fit_transform(X_train['text']).toarray()\n",
    "\n",
    "#vectorize test data (with transform only)\n",
    "X_test_bow = bow_vect.transform(X_test['text']).toarray()"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:53:40.393874Z",
     "start_time": "2025-10-29T11:53:40.385834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "as_df = pd.DataFrame(X_train_bow,columns=bow_vect.get_feature_names_out())\n",
    "as_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   ab  abacha  abandoned  abidjan  able  abroad  ac  accept  acceptance  \\\n",
       "0   0       0          0        0     0       0   0       0           0   \n",
       "1   0       0          0        0     1       0   0       0           0   \n",
       "2   0       0          0        0     0       0   0       0           0   \n",
       "3   0       0          0        0     0       0   0       0           0   \n",
       "4   0       0          0        0     0       0   0       0           0   \n",
       "\n",
       "   access  ...  xn  yahoo  year  yet  yf  york  yr  zf  zimbabwe  zz  \n",
       "0       0  ...   0      1     0    0   0     0   0   0         0   0  \n",
       "1       0  ...   0      0     0    0   0     0   0   0         0   0  \n",
       "2       0  ...   0      0     0    0   0     0   0   0         0   0  \n",
       "3       0  ...   0      0     0    0   0     0   0   0         0   0  \n",
       "4       0  ...   0      3     1    0   0     0   0   0         0   0  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ab</th>\n",
       "      <th>abacha</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abidjan</th>\n",
       "      <th>able</th>\n",
       "      <th>abroad</th>\n",
       "      <th>ac</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptance</th>\n",
       "      <th>access</th>\n",
       "      <th>...</th>\n",
       "      <th>xn</th>\n",
       "      <th>yahoo</th>\n",
       "      <th>year</th>\n",
       "      <th>yet</th>\n",
       "      <th>yf</th>\n",
       "      <th>york</th>\n",
       "      <th>yr</th>\n",
       "      <th>zf</th>\n",
       "      <th>zimbabwe</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "- Load the vectorizer\n",
    "\n",
    "- Vectorize all dataset\n",
    "\n",
    "- print the shape of the vetorized dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:54:46.673232Z",
     "start_time": "2025-10-29T11:54:46.587172Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# 1. Load the vectorizer and fit on training data (to learn vocabulary and IDF)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 2. Vectorize training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train['text']).toarray()\n",
    "\n",
    "# 3. Vectorize validation data (use transform, NOT fit_transform)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test['text']).toarray()\n",
    "\n",
    "# 4. Print shapes\n",
    "print(\"Train dataset TF-IDF shape:\", X_train_tfidf.shape)\n",
    "print(\"Validation dataset TF-IDF shape:\", X_test_tfidf.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset TF-IDF shape: (800, 28164)\n",
      "Validation dataset TF-IDF shape: (200, 28164)\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:55:50.972326Z",
     "start_time": "2025-10-29T11:55:50.956742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Convert to DataFrame for better visualization\n",
    "X_train_tfidf_df = pd.DataFrame(X_train_tfidf, columns=tfidf_vectorizer.get_feature_names_out())\n",
    "X_train_tfidf_df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    aa  aaa  aabeiawaeaambiqaceqedeqh  aac  aacw  aae  \\\n",
       "0  0.0  0.0                       0.0  0.0   0.0  0.0   \n",
       "1  0.0  0.0                       0.0  0.0   0.0  0.0   \n",
       "2  0.0  0.0                       0.0  0.0   0.0  0.0   \n",
       "3  0.0  0.0                       0.0  0.0   0.0  0.0   \n",
       "4  0.0  0.0                       0.0  0.0   0.0  0.0   \n",
       "\n",
       "   aaecaxeebsexbhjbuqdhcrmimoeifekrobhbcsmzuvavynlrchyknoel  aaegmdbsch  aaeh  \\\n",
       "0                                                0.0                0.0   0.0   \n",
       "1                                                0.0                0.0   0.0   \n",
       "2                                                0.0                0.0   0.0   \n",
       "3                                                0.0                0.0   0.0   \n",
       "4                                                0.0                0.0   0.0   \n",
       "\n",
       "   aaevvsghq  ...  zzwh  zzwqgb  zzwqgdg  zzwqgyw  zzwx  zzxh  \\\n",
       "0        0.0  ...   0.0     0.0      0.0      0.0   0.0   0.0   \n",
       "1        0.0  ...   0.0     0.0      0.0      0.0   0.0   0.0   \n",
       "2        0.0  ...   0.0     0.0      0.0      0.0   0.0   0.0   \n",
       "3        0.0  ...   0.0     0.0      0.0      0.0   0.0   0.0   \n",
       "4        0.0  ...   0.0     0.0      0.0      0.0   0.0   0.0   \n",
       "\n",
       "   zzxmsihdoawxlig  zzz  zzzahbxntxe  zzzj  \n",
       "0              0.0  0.0          0.0   0.0  \n",
       "1              0.0  0.0          0.0   0.0  \n",
       "2              0.0  0.0          0.0   0.0  \n",
       "3              0.0  0.0          0.0   0.0  \n",
       "4              0.0  0.0          0.0   0.0  \n",
       "\n",
       "[5 rows x 28164 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aabeiawaeaambiqaceqedeqh</th>\n",
       "      <th>aac</th>\n",
       "      <th>aacw</th>\n",
       "      <th>aae</th>\n",
       "      <th>aaecaxeebsexbhjbuqdhcrmimoeifekrobhbcsmzuvavynlrchyknoel</th>\n",
       "      <th>aaegmdbsch</th>\n",
       "      <th>aaeh</th>\n",
       "      <th>aaevvsghq</th>\n",
       "      <th>...</th>\n",
       "      <th>zzwh</th>\n",
       "      <th>zzwqgb</th>\n",
       "      <th>zzwqgdg</th>\n",
       "      <th>zzwqgyw</th>\n",
       "      <th>zzwx</th>\n",
       "      <th>zzxh</th>\n",
       "      <th>zzxmsihdoawxlig</th>\n",
       "      <th>zzz</th>\n",
       "      <th>zzzahbxntxe</th>\n",
       "      <th>zzzj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28164 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And the Train a Classifier?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T12:12:04.860661Z",
     "start_time": "2025-10-29T12:12:04.785146Z"
    }
   },
   "source": [
    "# We will use logistic regression because it's simple, fast, and surprisingly effective for text.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Defining classes\n",
    "y_train = y_train['label']\n",
    "y_test = y_test['label']\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Train the classifier on TF-IDF features\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred = clf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.955\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97       125\n",
      "           1       1.00      0.88      0.94        75\n",
      "\n",
      "    accuracy                           0.95       200\n",
      "   macro avg       0.97      0.94      0.95       200\n",
      "weighted avg       0.96      0.95      0.95       200\n",
      "\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Task - Implement a SPAM/HAM classifier\n",
    "\n",
    "https://www.kaggle.com/t/b384e34013d54d238490103bc3c360ce\n",
    "\n",
    "The classifier can not be changed!!! It must be the MultinimialNB with default parameters!\n",
    "\n",
    "Your task is to **find the most relevant features**.\n",
    "\n",
    "For example, you can test the following options and check which of them performs better:\n",
    "- Using \"Bag of Words\" only\n",
    "- Using \"TF-IDF\" only\n",
    "- Bag of Words + extra flags (money_mark, suspicious_words, text_len)\n",
    "- TF-IDF + extra flags\n",
    "\n",
    "\n",
    "You can work with teams of two persons (recommended)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-29T11:47:03.994077Z",
     "start_time": "2025-10-29T11:47:03.992233Z"
    }
   },
   "source": [
    "# Your code"
   ],
   "outputs": [],
   "execution_count": 23
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
