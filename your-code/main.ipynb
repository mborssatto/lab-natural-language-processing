{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:01.150173Z",
     "start_time": "2025-10-28T18:23:58.700926Z"
    }
   },
   "source": [
    "from IPython.display import display, HTML\n",
    "from keras.src.ops import dtype\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab | Natural Language Processing\n",
    "### SMS: SPAM or HAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:01.176453Z",
     "start_time": "2025-10-28T18:24:01.152688Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read Data for the Fraudulent Email Kaggle Challenge\n",
    "- Reduce the training set to speead up development. "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:01.215598Z",
     "start_time": "2025-10-28T18:24:01.180978Z"
    }
   },
   "source": [
    "## Read Data for the Fraudulent Email Kaggle Challenge\n",
    "data = pd.read_csv(\"../data/kg_train.csv\",encoding='latin-1')\n",
    "\n",
    "# Reduce the training set to speed up development. \n",
    "# Modify for final system\n",
    "data = data.head(1000)\n",
    "print(data.shape)\n",
    "data.fillna(\"\",inplace=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:01.226392Z",
     "start_time": "2025-10-28T18:24:01.222157Z"
    }
   },
   "cell_type": "code",
   "source": "data.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                text  label\n",
       "0  DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...      1\n",
       "1                                           Will do.      0\n",
       "2  Nora--Cheryl has emailed dozens of memos about...      0\n",
       "3  Dear Sir=2FMadam=2C I know that this proposal ...      1\n",
       "4                                                fyi      0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEAR SIR, STRICTLY A PRIVATE BUSINESS PROPOSAL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will do.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nora--Cheryl has emailed dozens of memos about...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dear Sir=2FMadam=2C I know that this proposal ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fyi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's divide the training and test set into two partitions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:01.309928Z",
     "start_time": "2025-10-28T18:24:01.243769Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data[['text']]\n",
    "y = data[['label']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:01.328874Z",
     "start_time": "2025-10-28T18:24:01.326188Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(X_train.shape)\n",
    "print(X_train.head())\n",
    "print(X_test.shape)\n",
    "print(X_test.head())\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 1)\n",
      "                                                  text\n",
      "29   ----------- REGARDS, MR NELSON SMITH.KINDLY RE...\n",
      "535  I have not been able to reach oscar this am. W...\n",
      "695  ; Huma Abedin B6I'm checking with Pat on the 5...\n",
      "557  I can have it announced here on Monday - can't...\n",
      "836      BANK OF AFRICAAGENCE SAN PEDRO14 BP 1210 S...\n",
      "(200, 1)\n",
      "                                                  text\n",
      "521  Dear Sir=2C I wish you go through this offer t...\n",
      "737  To take your mind off the Balkans for a second...\n",
      "740                       Pls keep the updates coming!\n",
      "660  </STRONG><STRONG>CHRIST BETHEL HOSPITAL<BR>11 ...\n",
      "411  sbwhoeopFriday February 5 2010 7:11 AMHRe: Bra...\n",
      "(800, 1)\n",
      "(200, 1)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:01.493700Z",
     "start_time": "2025-10-28T18:24:01.336880Z"
    }
   },
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "print(string.punctuation)\n",
    "print(stopwords.words(\"english\")[100:110])\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "snowball = SnowballStemmer('english')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "['needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on']\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, we have to clean the html code removing words\n",
    "\n",
    "- First we remove inline JavaScript/CSS\n",
    "- Then we remove html comments. This has to be done before removing regular tags since comments can contain '>' characters\n",
    "- Next we can remove the remaining tags"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:01.501887Z",
     "start_time": "2025-10-28T18:24:01.496753Z"
    }
   },
   "source": [
    "import re\n",
    "import html\n",
    "\n",
    "def remove_html_javascript(text):\n",
    "    # Remove <script> or <style> blocks\n",
    "    text = re.sub(r'<(script|style).*?>.*?</\\1>', '', text, flags=re.DOTALL)\n",
    "\n",
    "    #Unescape HTML entities (convert &nbsp; → space, &amp; → &, etc.)\n",
    "    text = html.unescape(text)\n",
    "\n",
    "    # Remove HTML comments\n",
    "    text = re.sub(r'<!--.*?-->', '', text, flags=re.DOTALL)\n",
    "\n",
    "    # Remove remaining HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(remove_html_javascript)\n",
    "X_test['text'] = X_test['text'].apply(remove_html_javascript)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:01.507754Z",
     "start_time": "2025-10-28T18:24:01.505001Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.head()",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  text\n",
       "29   ----------- REGARDS, MR NELSON SMITH.KINDLY RE...\n",
       "535  I have not been able to reach oscar this am. W...\n",
       "695  ; Huma Abedin B6I'm checking with Pat on the 5...\n",
       "557  I can have it announced here on Monday - can't...\n",
       "836      BANK OF AFRICAAGENCE SAN PEDRO14 BP 1210 S..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>----------- REGARDS, MR NELSON SMITH.KINDLY RE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>I have not been able to reach oscar this am. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>; Huma Abedin B6I'm checking with Pat on the 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>I can have it announced here on Monday - can't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>BANK OF AFRICAAGENCE SAN PEDRO14 BP 1210 S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove all the special characters\n",
    "    \n",
    "- Remove numbers\n",
    "    \n",
    "- Remove all single characters\n",
    " \n",
    "- Remove single characters from the start\n",
    "\n",
    "- Substitute multiple spaces with single space\n",
    "\n",
    "- Remove prefixed 'b'\n",
    "\n",
    "- Convert to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:01.584740Z",
     "start_time": "2025-10-28T18:24:01.526115Z"
    }
   },
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove all special characters except letters and spaces\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "\n",
    "    # Remove numbers (digits \\d)\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "\n",
    "    # Remove all single characters (isolated letters)\n",
    "    text = re.sub(r'\\b[a-zA-Z]\\b', ' ', text)\n",
    "\n",
    "    # Remove single characters from the start\n",
    "    text = re.sub(r'^[a-zA-Z]\\s+', '', text)\n",
    "\n",
    "    # Substitute multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Remove prefixed 'b' (e.g., b'text')\n",
    "    text = re.sub(r\"^b\\s+\", '', text)\n",
    "    text = re.sub(r\"^b'(.*)'$\", r'\\1', text)\n",
    "    text = re.sub(r'^b\"(.*)\"$', r'\\1', text)\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(clean_text)\n",
    "X_test['text'] = X_test['text'].apply(clean_text)"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:01.601623Z",
     "start_time": "2025-10-28T18:24:01.599335Z"
    }
   },
   "cell_type": "code",
   "source": "print(X_train.head)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                   text\n",
      "29   regards mr nelson smith kindly reply me on my ...\n",
      "535  have not been able to reach oscar this am we a...\n",
      "695  huma abedin checking with pat on the will work...\n",
      "557     can have it announced here on monday can today\n",
      "836  bank of africaagence san pedro bp san pedro co...\n",
      "..                                                 ...\n",
      "106  adama ibrahim tout savoir sur la curit de votr...\n",
      "270              what does that mean for our schedules\n",
      "860  dear friend my compliment to you guess this le...\n",
      "435  dear president fdirector my name is mr micheal...\n",
      "102  let me know if today or tomorrow works for you...\n",
      "\n",
      "[800 rows x 1 columns]>\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Now let's work on removing stopwords\n",
    "Remove the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:01.717433Z",
     "start_time": "2025-10-28T18:24:01.604829Z"
    }
   },
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "def clean_stopwords(text):\n",
    "    words = [w for w in text.split() if w not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(clean_stopwords)\n",
    "X_test['text'] = X_test['text'].apply(clean_stopwords)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:01.723032Z",
     "start_time": "2025-10-28T18:24:01.720541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(X_train.head)\n",
    "print(X_test.head)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                                                   text\n",
      "29   regards mr nelson smith kindly reply private e...\n",
      "535         able reach oscar supposed send pdb receive\n",
      "695  huma abedin checking pat work jack jake rest a...\n",
      "557                             announced monday today\n",
      "836  bank africaagence san pedro bp san pedro cote ...\n",
      "..                                                 ...\n",
      "106  adama ibrahim tout savoir sur la curit de votr...\n",
      "270                                     mean schedules\n",
      "860  dear friend compliment guess letter may come s...\n",
      "435  dear president fdirector name mr micheal ipenz...\n",
      "102  let know today tomorrow works would rather fin...\n",
      "\n",
      "[800 rows x 1 columns]>\n",
      "<bound method NDFrame.head of                                                   text\n",
      "521  dear sir wish go offer consider partner ei mr ...\n",
      "737  take mind balkans second see great plug global...\n",
      "740                            pls keep updates coming\n",
      "660  christ bethel hospital rue abobote abidjanivor...\n",
      "411  sbwhoeopfriday february amhre bravo brava issu...\n",
      "..                                                 ...\n",
      "408                   sorry yes exactlywe shy tomorrow\n",
      "332  dear cgood day ei know message come suprise co...\n",
      "208                                                fyi\n",
      "613  greetings dear friend please permit contact me...\n",
      "78                     car way airport talk call berry\n",
      "\n",
      "[200 rows x 1 columns]>\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tame Your Text with Lemmatization\n",
    "Break sentences into words, then use lemmatization to reduce them to their base form (e.g., \"running\" becomes \"run\"). See how this creates cleaner data for analysis!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:02.605221Z",
     "start_time": "2025-10-28T18:24:01.725772Z"
    }
   },
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "X_train['text'] = X_train['text'].apply(lemmatizer.lemmatize)\n",
    "X_test['text'] = X_test['text'].apply(lemmatizer.lemmatize)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:02.641692Z",
     "start_time": "2025-10-28T18:24:02.639496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"X_train_lemmatized\")\n",
    "print(X_train.head())\n",
    "print(\"X_test_lemmatized\")\n",
    "print(X_test.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_lemmatized\n",
      "                                                  text\n",
      "29   regards mr nelson smith kindly reply private e...\n",
      "535         able reach oscar supposed send pdb receive\n",
      "695  huma abedin checking pat work jack jake rest a...\n",
      "557                             announced monday today\n",
      "836  bank africaagence san pedro bp san pedro cote ...\n",
      "X_test_lemmatized\n",
      "                                                  text\n",
      "521  dear sir wish go offer consider partner ei mr ...\n",
      "737  take mind balkans second see great plug global...\n",
      "740                            pls keep updates coming\n",
      "660  christ bethel hospital rue abobote abidjanivor...\n",
      "411  sbwhoeopfriday february amhre bravo brava issu...\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words\n",
    "Let's get the 10 top words in ham and spam messages (**EXPLORATORY DATA ANALYSIS**)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:02.659684Z",
     "start_time": "2025-10-28T18:24:02.646134Z"
    }
   },
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "def get_top_n_words(text_series, n=10):\n",
    "    all_text = ' '.join(text_series)\n",
    "    words = all_text.split()\n",
    "    word_counts = Counter(words)\n",
    "    return word_counts.most_common(n)\n",
    "\n",
    "# Convert X_train and y_train to DataFrame\n",
    "df_train = pd.concat([X_train['text'], y_train['label']], axis=1)\n",
    "df_test = pd.concat([X_test['text'], y_test['label']], axis=1)\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "\n",
    "# Top 10 words in ham messages\n",
    "top_10_ham = get_top_n_words(df_all[df_all['label'] == 0]['text'])\n",
    "top_10_spam = get_top_n_words(df_all[df_all['label'] == 1]['text'])\n",
    "\n",
    "top_10_ham = pd.DataFrame(top_10_ham, columns=['words', 'count'])\n",
    "top_10_spam = pd.DataFrame(top_10_spam, columns=['words', 'count'])\n",
    "\n",
    "print(\"Top 10 Ham Words:\")\n",
    "print(top_10_ham)\n",
    "print(\"Top 10 Spam Words:\")\n",
    "print(top_10_spam)\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Ham Words:\n",
      "       words  count\n",
      "0         pm    127\n",
      "1      state    113\n",
      "2      would    107\n",
      "3  president     98\n",
      "4         mr     86\n",
      "5      obama     84\n",
      "6    percent     81\n",
      "7       call     78\n",
      "8  secretary     76\n",
      "9         us     76\n",
      "Top 10 Spam Words:\n",
      "         words  count\n",
      "0        money    981\n",
      "1      account    836\n",
      "2         bank    780\n",
      "3           us    734\n",
      "4  transaction    538\n",
      "5     business    514\n",
      "6      country    475\n",
      "7         fund    474\n",
      "8      million    439\n",
      "9     transfer    421\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra features"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:02.678187Z",
     "start_time": "2025-10-28T18:24:02.668050Z"
    }
   },
   "source": [
    "# We add to the original dataframe two additional indicators (money symbols and suspicious words).\n",
    "money_simbol_list = \"|\".join([\"euro\",\"dollar\",\"pound\",\"€\",r\"\\$\"])\n",
    "suspicious_words = \"|\".join([\"free\",\"cheap\",\"sex\",\"money\",\"account\",\"bank\",\"fund\",\"transfer\",\"transaction\",\"win\",\"deposit\",\"password\"])\n",
    "\n",
    "X_train['money_mark'] = X_train['text'].str.contains(money_simbol_list)*1\n",
    "X_train['suspicious_words'] = X_train['text'].str.contains(suspicious_words)*1\n",
    "X_train['text_len'] = X_train['text'].apply(lambda x: len(x))\n",
    "\n",
    "X_test['money_mark'] = X_test['text'].str.contains(money_simbol_list)*1\n",
    "X_test['suspicious_words'] = X_test['text'].str.contains(suspicious_words)*1\n",
    "X_test['text_len'] = X_test['text'].apply(lambda x: len(x))\n",
    "\n",
    "X_train.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                  text  money_mark  \\\n",
       "29   regards mr nelson smith kindly reply private e...           0   \n",
       "535         able reach oscar supposed send pdb receive           0   \n",
       "695  huma abedin checking pat work jack jake rest a...           0   \n",
       "557                             announced monday today           0   \n",
       "836  bank africaagence san pedro bp san pedro cote ...           1   \n",
       "\n",
       "     suspicious_words  text_len  \n",
       "29                  0        80  \n",
       "535                 0        42  \n",
       "695                 0        76  \n",
       "557                 0        22  \n",
       "836                 1      1062  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>money_mark</th>\n",
       "      <th>suspicious_words</th>\n",
       "      <th>text_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>regards mr nelson smith kindly reply private e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>able reach oscar supposed send pdb receive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>huma abedin checking pat work jack jake rest a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>announced monday today</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>bank africaagence san pedro bp san pedro cote ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How would work the Bag of Words with Count Vectorizer concept?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:02.698549Z",
     "start_time": "2025-10-28T18:24:02.697316Z"
    }
   },
   "source": [
    "# Your code"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "- Load the vectorizer\n",
    "\n",
    "- Vectorize all dataset\n",
    "\n",
    "- print the shape of the vetorized dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:02.721059Z",
     "start_time": "2025-10-28T18:24:02.719463Z"
    }
   },
   "source": [
    "# Your code"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And the Train a Classifier?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:02.725882Z",
     "start_time": "2025-10-28T18:24:02.724621Z"
    }
   },
   "source": [
    "# Your code"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Task - Implement a SPAM/HAM classifier\n",
    "\n",
    "https://www.kaggle.com/t/b384e34013d54d238490103bc3c360ce\n",
    "\n",
    "The classifier can not be changed!!! It must be the MultinimialNB with default parameters!\n",
    "\n",
    "Your task is to **find the most relevant features**.\n",
    "\n",
    "For example, you can test the following options and check which of them performs better:\n",
    "- Using \"Bag of Words\" only\n",
    "- Using \"TF-IDF\" only\n",
    "- Bag of Words + extra flags (money_mark, suspicious_words, text_len)\n",
    "- TF-IDF + extra flags\n",
    "\n",
    "\n",
    "You can work with teams of two persons (recommended)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-28T18:24:02.735873Z",
     "start_time": "2025-10-28T18:24:02.734558Z"
    }
   },
   "source": [
    "# Your code"
   ],
   "outputs": [],
   "execution_count": 21
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
